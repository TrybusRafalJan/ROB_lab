% malutki plik do uruchomienia funkcji pdf
load pdf_test.txt
size(pdf_test)

% ile jest klas?
labels = unique(pdf_test(:,1))

% ile jest prï¿½bek w kaï¿½dej klasie?
[labels'; pdf_test(:,1) == labels')] %suma elementï¿½w gdy wartoï¿½ï¿½ = label(1,2)
		  % ^^^ dobrze byï¿½oby pomyï¿½leï¿½ o tym wyraï¿½eniu
      %w pdf_test(:,1) sï¿½ etykiety w labels' rodzaje tych etykiet

% jak ukï¿½adajï¿½ siï¿½ prï¿½bki?
plot2features(pdf_test, 2, 3)
%plot 2 i 3 kolumny w 1-szej sï¿½ etykiety


pdfindep_para = para_indep(pdf_test)
% para_indep jest do zaimplementowania, tak ï¿½eby dawaï¿½a:

% pdfindep_para =
%  scalar structure containing the fields:
%    labels =
%       1
%       2
%    mu =
%       0.7970000   0.8200000
%      -0.0090000   0.0270000
%    sig =
%       0.21772   0.19172
%       0.19087   0.27179

% teraz do zaimplementowania jest sama funkcja liczï¿½ca pdf 
%  przygotowujï¿½c te dane skorzystaï¿½em z funkcji normpdf
%  ta funkcja jest zdefiniowana w pakiecie statistics i w mojej
%  lokalnej konfiguracji muszï¿½ najpierw zaï¿½adowaï¿½ ten pakiet:

pkg load statistics % moï¿½e nie byï¿½ konieczne
pi_pdf = pdf_indep(pdf_test([2 7 12 17],2:end), pdfindep_para)

%pi_pdf =
%  1.4700e+000  4.5476e-007
%  3.4621e+000  4.9711e-005
%  6.7800e-011  2.7920e-001
%  5.6610e-008  1.8097e+000

% wielowymiarowy rozkï¿½ad normalny - parametry ...

pdfmulti_para = para_multi(pdf_test)

%pdfmulti_para =
%  scalar structure containing the fields:
%    labels =
%       1
%       2
%    mu =
%       0.7970000   0.8200000
%      -0.0090000   0.0270000
%    sig =
%    ans(:,:,1) =
%       0.047401   0.018222
%       0.018222   0.036756
%    ans(:,:,2) =
%       0.036432  -0.033186
%      -0.033186   0.073868  

% ... i funkcja liczï¿½ca gï¿½stoï¿½ï¿½
% paradoksalnie sytuacja jest tutaj prostsza, bo w pakiecie
% macie Paï¿½stwo plik mvnpdf.m zawierajï¿½cy funkcjï¿½, ktï¿½ra
% liczy wielowymiarowï¿½ funkcjï¿½ gï¿½stoï¿½ci prawdobieï¿½stwa rozkï¿½adu
% normalnego

pm_pdf = pdf_multi(pdf_test([2 7 12 17],2:end), pdfmulti_para)

%pm_pdf =
%  7.9450e-001  6.5308e-017
%  3.9535e+000  3.8239e-013
%  1.6357e-009  8.6220e-001
%  4.5833e-006  2.8928e+000

% parametry dla aproksymacji oknem Parzena
% tï¿½ funkcjï¿½ macie Paï¿½stwo gotowï¿½ - uï¿½ywam w niej cell arrays
% warto doczytaï¿½: https://octave.org/doc/v4.2.1/Cell-Arrays.html

pdfparzen_para = para_parzen(pdf_test, 0.5)
									 % ^^^ szerokoï¿½ï¿½ okna

%pdfparzen_para =
%  scalar structure containing the fields:
%    labels =
%       1
%       2
%    samples =
%    {
%      [1,1] =
%         1.10000   0.95000
%         0.98000   0.61000
% .....
%         0.69000   0.93000
%         0.79000   1.01000
%      [2,1] =
%        -0.010000   0.380000
%         0.250000  -0.440000
% .....
%        -0.110000   0.030000
%         0.120000  -0.090000
%    }
%    parzenw =  0.50000

pp_pdf = pdf_parzen(pdf_test([2 7 12 17],2:end), pdfparzen_para)

%pp_pdf =
%  9.7779e-001  6.1499e-008
%  2.1351e+000  4.2542e-006
%  9.4059e-010  9.8823e-001
%  2.0439e-006  1.9815e+000


% wreszcie moï¿½na zajï¿½ï¿½ siï¿½ kartami!
% wczeï¿½niejszy fragment moï¿½na spokojnie usunï¿½ï¿½ po uruchomieniu
% funkcji liczï¿½cych pdf
[train test] = load_cardsuites_data();

% pierwszy rzut oka na dane
size(train)
size(test)
labels = unique(train(:,1))
unique(test(:,1))
[labels'; sum(train(:,1) == labels')]

% pierwszym zadaniem po zaï¿½adowaniu danych jest sprawdzenie,
% czy w zbiorze uczï¿½cym nie ma prï¿½bek odstajï¿½cych
% do realizacji tego zadania przydadzï¿½ siï¿½ funkcje liczï¿½ce
% proste statystyki: mean, median, std, 
% wyï¿½wietlenie histogramu cech(y): hist
% spojrzenie na dwie cechy na raz: plot2features (dostarczona w pakiecie)

[mean(train); median(train)]
t =abs(mean(train) - median(train))
% hist domyï¿½lnie dzieli zakres wartoï¿½ci na 10 koszykï¿½w
% wyï¿½wietlenie w ten sposï¿½b 8 etykiet doï¿½ï¿½ dobrze ilustruje 
% dziaï¿½anie hist
hist(train(:,1))

% to nie sï¿½ cechy, ktï¿½re wykorzystaï¿½bym do klasyfikacji - moï¿½na
% znaleï¿½ï¿½ duï¿½o lepsze; do sprawdzania, czy sï¿½ wartoï¿½ci odstajï¿½ce
% nawet te cechy wystarczï¿½


% do identyfikacji odstajï¿½cych prï¿½bek doskonale nadajï¿½ siï¿½ wersje
% funkcji min i max z dwoma argumentami wyjï¿½ciowymi

[mv midx] = min(train)

% poniewaï¿½ wartoï¿½ci minimalne czy maksymalne da siï¿½ wyznaczyï¿½ zawsze,
% dobrze zweryfikowaï¿½ ich odstawanie spoglï¿½dajï¿½c przynajmniej na sï¿½siadï¿½w
% podejrzanej prï¿½bki w zbiorze uczï¿½cym

% powiedzmy, ï¿½e podejrzana jest prï¿½bka 41
midx_1 = 642
train(midx-1:midx+1, :)

midx_2 = 186
train(midx-1:midx+1, :)

% jeï¿½li nabraï¿½em przekonania, ï¿½e prï¿½bka midx jest do usuniï¿½cia, to:
size(train)
train(midx_1, :) = []; % usuniï¿½cie wiersza midx z macierzy
size(train)

size(train)
train(midx_2, :) = []; % usuniï¿½cie wiersza midx z macierzy
size(train)

[mean(train); median(train)]
t =abs(mean(train) - median(train))

plot2features(train, 2, 4) 


% procedurï¿½ szukania i usuwania wartoï¿½ci odstajï¿½cych trzeba powtarzaï¿½ do skutku

% po usuniï¿½ciu wartoï¿½ci odstajï¿½cych moï¿½na zajï¿½ï¿½ siï¿½ wyborem DWï¿½CH cech dla klasyfikacji
% w tym przypadku w zupeï¿½noï¿½ci wystarczy pooglï¿½daï¿½ wykresy dwï¿½ch cech i wybraï¿½ te, ktï¿½re
% dajï¿½ w miarï¿½ dobrze odseparowane od siebie klasy

% Po ustaleniu cech (dokï¿½adniej: indeksï¿½w kolumn, w ktï¿½rych cechy siedzï¿½):
first_idx = 2;
second_idx = 5;
train = train(:, [1 first_idx second_idx]);
test = test(:, [1 first_idx second_idx]);

% to nie jest najrosï¿½dniejszy wybï¿½r; 4 i 6 na pewno trzeba zmieniï¿½

% tutaj jawnie tworzï¿½ strukturï¿½ z parametrami dla klasyfikatora Bayesa 
% (po prawdzie, to dla funkcji liczï¿½cej gï¿½stoï¿½ï¿½ prawdobieï¿½stwa) z zaï¿½oï¿½eniem,
% ï¿½e cechy sï¿½ niezaleï¿½ne

pdfindep_para = para_indep(train); %obliczone wczeï¿½niej funkcjie
pdfmulti_para = para_multi(train); 
pdfparzen_para = para_parzen(train, 0.0001); 
% w sprawozdaniu trzeba podawaï¿½ szerokoï¿½ï¿½ okna (nie liczymy tego parametru z danych!)	
%%%%TUTAJ!!!

% wyniki do punktu 3
base_ercf = zeros(1,3)
base_ercf(1) = mean(bayescls(test(:,2:end), @pdf_indep, pdfindep_para) != test(:,1));
base_ercf(2) = mean(bayescls(test(:,2:end), @pdf_multi, pdfmulti_para) != test(:,1));
base_ercf(3) = mean(bayescls(test(:,2:end), @pdf_parzen, pdfparzen_para) != test(:,1));
base_ercf

%%%%%%%% TESTY RÃ“Å»NYCH PARAMETRÃ“W %%%%%%%


[train test] = load_cardsuites_data();

midx_1 = 642
train(midx_1, :) = []; % usuniï¿½cie wiersza midx z macierzy  %%% wyrzucenie prÃ³bek odstajÄ…cych

midx_2 = 186
train(midx_2, :) = []; % usuniï¿½cie wiersza midx z macierzy


plot2features(train, 2, 4) 

first_idx = 2;
second_idx = 4;
train = train(:, [1 first_idx second_idx]); %%%%% wybÃ³r cech do budowy klasyfikatora
test = test(:, [1 first_idx second_idx]);

pkg load statistics
pdfindep_para = para_indep(train); %obliczone wczeï¿½niej funkcjie
pdfmulti_para = para_multi(train); 
pdfparzen_para = para_parzen(train, 0.001); 



base_ercf = zeros(1,3)
base_ercf(1) = mean(bayescls(test(:,2:end), @pdf_indep, pdfindep_para) != test(:,1));
base_ercf(2) = mean(bayescls(test(:,2:end), @pdf_multi, pdfmulti_para) != test(:,1));
base_ercf(3) = mean(bayescls(test(:,2:end), @pdf_parzen, pdfparzen_para) != test(:,1));
base_ercf

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% W kolejnym punkcie przyda siï¿½ funkcja reduce, ktï¿½ra redukuje liczbï¿½ prï¿½bek w poszczegï¿½lnych
% klasach (w tym przypadku redukcja bï¿½dzie taka sama we wszystkich klasach - ZBIORU UCZï¿½CEGO)
% Poniewaï¿½ reduce ma losowaï¿½ prï¿½bki, to eksperyment naleï¿½y powtï¿½rzyï¿½ 5 (lub wiï¿½cej) razy
% W sprawozdaniu proszï¿½ podaï¿½ tylko wartoï¿½ï¿½ ï¿½redniï¿½ i odchylenie standardowe wspï¿½ï¿½czynnika bï¿½ï¿½du
% Wyobraï¿½am sobie, ï¿½e w kaï¿½dym powtï¿½rzeniu eksperymentu tworzï¿½
% nowï¿½ wersjï¿½ zbioru uczï¿½cego:
%   reduced_train = reduce(train, parts(i) * ones(1, class_count))

parts = [0.1 0.25 0.5];
rep_cnt = 5; % przynajmniej

% YOUR CODE GOES HERE 
%

train(:, 1); % same etykiety
unique(train(:, 1));
class = rows(unique(train(:, 1))); % licbza klas = 8

% inicjalizacja - iloÅ›Ä‡ powtÃ³rzeÅ„ na iloÅ›Ä‡ podzieleÅ„
array_indep = zeros(rep_cnt, columns(parts)) 
array_multi = zeros(rep_cnt, columns(parts))
array_parzen = zeros(rep_cnt, columns(parts))

for partNr = 1:columns(parts) % iteracja po rÃ³Å¼nych iloÅ›ciach podziaÅ‚u
  part = parts(partNr);
  for i = 1:rep_cnt  %iteracja po iloÅ›ciach powtÃ³rzeÅ„
    
    reduced_train = reduce(train, part * ones(1, class));
    
    pdfindep_para = para_indep(reduced_train);
    pdfmulti_para = para_multi(reduced_train);
    pdfparzen_para = para_parzen(reduced_train, 0.001);
    
    array_indep(i, partNr) = mean(bayescls(test(:,2:end), @pdf_indep, pdfindep_para) != test(:,1));
    array_multi(i, partNr) = mean(bayescls(test(:,2:end), @pdf_multi, pdfmulti_para) != test(:,1));
    array_parzen(i, partNr) = mean(bayescls(test(:,2:end), @pdf_parzen, pdfparzen_para) != test(:,1));
  end  
end
% ^^ oblicza iloÅ›Ä‡ poprawnych zaklasyfikowaÅ„

%srednie dla 5 pomiarow
mean_indep = mean(array_indep);
std_indep = std(array_indep);

mean_multi = mean(array_multi);
std_multi = std(array_multi);

mean_parzen = mean(array_parzen);
std_parzen = std(array_parzen);

% Punkt 5 dotyczy jedynie klasyfikatora z oknem Parzena (na peï¿½nym zbiorze uczï¿½cym)

parzen_widths = [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075 0.01];
parzen_res = zeros(1, columns(parzen_widths));

% YOUR CODE GOES HERE 
%

 for j = 1:columns(parzen_widths)
  

  pdfparzen_para = para_parzen(train, parzen_widths(j));  
  parzen_res(1, j) = mean(bayescls(test(:,2:end), @pdf_parzen, pdfparzen_para) != test(:,1));
  
end


[parzen_widths; parzen_res]
% Tu aï¿½ prosi siï¿½ doï¿½oï¿½yï¿½ do danych numerycznych wykres
semilogx(parzen_widths, parzen_res)

% W punkcie 6 redukcja dotyczy ZBIORU TESTOWEGO, natomiast warto
% zadbaï¿½ o to, ï¿½eby parametry dla funkcji pdf byï¿½y policzone
% na caï¿½ym zbiorze uczï¿½cym (po poprzednich eksperymentach tak 
% raczej nie jest)
% Poniewaï¿½ losujemy prï¿½bki, to wypada powtï¿½rzyï¿½ eksperyment 
% stosownï¿½ liczbï¿½ razy i uï¿½redniï¿½ wyniki
% reduced_test = reduce(test, parts) 

apriori = [0.165 0.085 0.085 0.165 0.165 0.085 0.085 0.165]; % ró¿ne prawdopodobieñstwa apriori
parts = [1.0 0.5 0.5 1.0 1.0 0.5 0.5 1.0]; %podzia³
rep_cnt = 5; % powtï¿½rka, ï¿½eby nie zapomnieï¿½

% YOUR CODE GOES HERE 
%

array_indep = zeros(rep_cnt, 1); %inicjalizacja iloœæ powtórzeñ x 1 ( w ka¿deym inna wart)
array_multi = zeros(rep_cnt, 1);
array_parzen = zeros(rep_cnt, 1);

for i = 1:rep_cnt
    
    reduced_test = reduce(test, parts); %redukcja zbioru testowego
	  labelsOnly = reduced_test(:, 1) % tylko kolumna z etykiet¹
    
    pdfindep_para = para_indep(train); % nowe wartoœci paramterów
    pdfmulti_para = para_multi(train);
    pdfparzen_para = para_parzen(train, 0.001);
    
    
    array_indep(i, 1) = mean(bayescls(reduced_test(:,2:end), @pdf_indep, pdfindep_para, apriori) != reduced_test(:,1));
    
    
    array_multi(i, 1) = mean(bayescls(reduced_test(:,2:end), @pdf_multi, pdfmulti_para, apriori) != reduced_test(:,1));
   
    
   
    array_parzen(i, 1) = mean(bayescls(reduced_test(:,2:end), @pdf_parzen, pdfparzen_para, apriori) != reduced_test(:,1));
    
    
end

mean_indep = mean(array_indep);
std_indep = std(array_indep);

mean_multi = mean(array_multi);
std_multi = std(array_multi);

mean_parzen = mean(array_parzen);
std_parzen = std(array_parzen);

[[mean_indep std_indep],[mean_multi std_multi], [mean_parzen std_parzen]]


% W ostatnim punkcie trzeba zastanowiï¿½ siï¿½ nad normalizacjï¿½
std(train(:,2:end))
% Moï¿½e warto sprawdziï¿½, jak to wyglï¿½da w poszczegï¿½lnych klasach?

% Normalizacja potrzebna?
% Jeï¿½li TAK, to jej parametry sï¿½ liczone TYLKO na zbiorze uczï¿½cym
% Procedura normalizacji jest aplikowana do zbioru uczï¿½cego i testowego
% Poniewaï¿½ zbiory uczï¿½cy i testowy sï¿½ przyzwoitej wielkoï¿½ci 
% klasyfikujecie Paï¿½stwo testowy za pomocï¿½ uczï¿½cego (nie ma
% potrzeby uï¿½ycia leave-one-out)


% YOUR CODE GOES HERE 
%
%%%NORMALIZAJCA%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%WCZYTANIE DANYCH%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
load train.txt; %wczytanie danych
load test.txt;

first_idx = 2; % ponowne ustawienie cech 2 i 4
second_idx = 4;
train = train(:, [1 first_idx second_idx]);
test = test(:, [1 first_idx second_idx]);

midx_1 = 642
midx_2 = 186



train(midx_1, :) = []; 

train(midx_2, :) = []; 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

atrr1_mean = mean(train(:,2));
atrr1_std = std(train(:,2));

atrr2_mean = mean(train(:,3));
atrr2_std = std(train(:,3));


trainNorm = zeros(size(train));


trainNorm(:, 1) = train(:, 1);
%normalizacja
trainNorm(:, 2) = (train(:, 2) - atrr1_mean)/atrr1_std;
trainNorm(:, 3) = (train(:, 3) - atrr2_mean)/atrr2_std;

%dane testowe znormalizowane
testNorm = zeros(size(test));

testNorm(:, 1) = test(:, 1);
testNorm(:, 2) = (test(:, 2) - atrr1_mean)/atrr1_std;
testNorm(:, 3) = (test(:, 3) - atrr2_mean)/atrr2_std;



errorCount = 0;

for i = 1:rows(test)
  
  testsample = testNorm(i, 2:end);
  
  res = cls1nn(trainNorm, testsample);
  
  if res != test(i, 1)
    errorCount++;
  end
  
end

totalERROR = errorCount/rows(test)

%%%BEZ NORMALIZAJCji%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
load train.txt; %wczytanie danych
load test.txt;

first_idx = 2; % ponowne ustawienie cech 2 i 4
second_idx = 4;
train = train(:, [1 first_idx second_idx]);
test = test(:, [1 first_idx second_idx]);

midx_1 = 642
midx_2 = 186



train(midx_1, :) = []; 

train(midx_2, :) = []; 

errorCount = 0;

for j = 1:rows(test)
  
  test_probka = test(j, 2:end);
  
  res = cls1nn(train, test_probka);
  
  if res != test(j, 1)
    errorCount++;
  end
  
end

TotalERROR = errorCount/rows(test)



